"""
Pawa AI Backend - Vercel Serverless Function
All endpoints in one file for Vercel deployment
"""
import os
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import google.generativeai as genai

# Initialize FastAPI
app = FastAPI()

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configure Gemini
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY", "AIzaSyBzT0i4WjPexzHG-QR5RIARNLX0ZOjK8uM")
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)

# Models
class GeminiMessage(BaseModel):
    role: str
    content: str

class GeminiChatRequest(BaseModel):
    message: str
    conversation_history: List[GeminiMessage] = []
    model: str = "gemini-2.0-flash-exp"
    temperature: float = 0.7

class ChatResponse(BaseModel):
    response: str
    model_used: str = "gemini-2.0-flash-exp"

# Health check
@app.get("/api/health")
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "service": "Pawa AI Backend",
        "version": "2.0.0",
        "gemini_configured": bool(GOOGLE_API_KEY),
        "platform": "Vercel Serverless"
    }

# Gemini chat endpoint
@app.post("/api/gemini/chat")
@app.post("/gemini/chat")
async def gemini_chat(request: GeminiChatRequest):
    if not GOOGLE_API_KEY:
        raise HTTPException(status_code=500, detail="GOOGLE_API_KEY not configured")

    try:
        model = genai.GenerativeModel(
            model_name=request.model,
            generation_config={
                "temperature": request.temperature,
                "top_p": 0.95,
                "top_k": 40,
                "max_output_tokens": 8192,
            }
        )

        history = []
        for msg in request.conversation_history:
            history.append({
                "role": msg.role if msg.role != "assistant" else "model",
                "parts": [msg.content]
            })

        chat = model.start_chat(history=history)
        response = chat.send_message(request.message)

        return ChatResponse(
            response=response.text,
            model_used=request.model
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Gemini API error: {str(e)}")

# Root endpoint
@app.get("/")
@app.get("/api")
async def root():
    return {
        "service": "Pawa AI Backend",
        "version": "2.0.0",
        "platform": "Vercel Serverless",
        "features": ["2M token context with Gemini"],
        "endpoints": {
            "health": "/api/health",
            "chat": "/api/gemini/chat (POST)"
        }
    }

# Vercel handler
from mangum import Mangum
handler = Mangum(app)
